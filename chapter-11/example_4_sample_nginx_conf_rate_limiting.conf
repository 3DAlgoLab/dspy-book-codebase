worker_processes auto;

events {
    worker_connections 1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    # =========================================================================
    # 1. IDENTITY RESOLUTION (API Key vs IP)
    # =========================================================================
    # Extract the API key from the Authorization header (Bearer sk-...).
    # If the header is missing or malformed, fall back to the IP address.
    # This ensures corporate users sharing an IP aren't throttled together
    # if they have different API keys.
    map $http_authorization $client_id {
        default                 $binary_remote_addr; # Fallback to IP
        "~^Bearer\s+(.*)$"      $1;                  # Capture the key
    }

    # =========================================================================
    # 2. RATE LIMIT ZONES
    # =========================================================================
    
    # Zone A: Global Safety Net
    # Protects the backend from total collapse (DDoS).
    # Limit: 100 requests/sec total across ALL users.
    limit_req_zone "global" zone=global_zone:10m rate=100r/s;

    # Zone B: Expensive Inference (Per User/Key)
    # Tighter limits for expensive LLM endpoints.
    # Limit: 5 requests/sec per user. 
    limit_req_zone $client_id zone=inference_zone:10m rate=5r/s;

    # Zone C: General/Health (Per User/Key)
    # looser limits for lightweight endpoints.
    # Limit: 20 requests/sec per user.
    limit_req_zone $client_id zone=general_zone:10m rate=20r/s;

    # =========================================================================
    # 3. UPSTREAM CONFIGURATION
    # =========================================================================
    upstream llm_backend {
        server 127.0.0.1:8080;
        # keepalive 32; # Keep connections open for performance
    }

    server {
        listen 80;
        server_name api.example.com;

        # =========================================================================
        # 4. GLOBAL SECURITY & PERFORMANCE SETTINGS
        # =========================================================================
        
        # Block Context Window Stuffing Attacks
        # Limit bodies to 1MB (approx 250k tokens). 
        # Prevents attackers from sending massive prompts to spike compute costs.
        client_max_body_size 1m;

        # LLM Timeout Configuration
        # LLMs are slow. Default 60s is often too short for RAG/CoT pipelines.
        proxy_connect_timeout 60s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # Streaming Configuration (CRITICAL for SSE/streaming)
        # Disable buffering so tokens are sent to the client immediately
        # as they are generated, rather than waiting for a chunk.
        proxy_buffering off;
        proxy_cache off;
        
        # Pass headers needed for WebSockets/SSE
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # =========================================================================
        # 5. ENDPOINT ROUTING
        # =========================================================================

        # High-Cost Endpoint: Chat Completions
        location /v1/chat/completions {
            # 1. Check Global Limit (DDoS protection)
            limit_req zone=global_zone burst=50 nodelay;
            
            # 2. Check User Limit (Cost protection)
            # burst=5 allows short spikes, nodelay prevents artificial latency
            limit_req zone=inference_zone burst=5 nodelay;

            proxy_pass http://llm_backend;
        }

        # Low-Cost Endpoint: Health/Status
        location /health {
            # Use the general zone with higher limits
            limit_req zone=general_zone burst=10 nodelay;
            
            return 200 '{"status": "ok"}';
        }

        # Default fallback for other API routes
        location / {
            limit_req zone=general_zone burst=10 nodelay;
            proxy_pass http://llm_backend;
        }

        # =========================================================================
        # 6. CUSTOM ERROR HANDLING
        # =========================================================================
        
        # Redirect rate limit errors to a named location
        error_page 429 @limit_hit;

        location @limit_hit {
            default_type application/json;
            
            # Standard header for automated clients (e.g. OpenAI SDK, LangChain)
            # Tells them strictly to wait 5 seconds before retrying.
            add_header Retry-After 5 always;
            
            # CORS headers if needed for browser clients
            add_header 'Access-Control-Allow-Origin' '*' always;

            return 429 '{"error": { "code": 429, "message": "Rate limit exceeded", "type": "too_many_requests_error" }}';
        }
    }
}